{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2326db57",
   "metadata": {},
   "source": [
    "# Evaluation: Completeness\n",
    "\n",
    "Part II of the computational evaluation of AI-generated linked data for [Linking Anthropology's Data and Archives (LADA)](https://ischool.umd.edu/projects/building-a-sustainable-future-for-anthropologys-archives-researching-primary-source-data-lifecycles-infrastructures-and-reuse/), focused on completeness (e.g., metadata fields are not empty or 'unknown,' URLs in field values are valid).\n",
    "\n",
    "---\n",
    "\n",
    "**Table of Contents:**\n",
    "\n",
    "I. [Data Loading](#data-loading)\n",
    "\n",
    "II. [Completeness](#completeness)\n",
    "\n",
    "  * [Content of Fields](#content-of-fields)\n",
    "\n",
    "    * [Dublin Core](#dublin-core)\n",
    "\n",
    "    * [JSON-LD](#json-ld)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeea65d6",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import config\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from urllib.request import Request, urlopen\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "from pyld import jsonld\n",
    "from lxml import etree\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bd2e97",
   "metadata": {},
   "source": [
    "Create variables to reference existing directories and files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b91bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_path = \"cleaned/dublin_core/\"  # XML data files\n",
    "schema_path = \"cleaned/schema_org/\"   # JSON data files\n",
    "cidoc_path = \"cleaned/cidoc_crm/\"     # JSON data files\n",
    "\n",
    "dublin_t1_dir = config.task1_data+dublin_path\n",
    "schema_t1_dir = config.task1_data+schema_path\n",
    "cidoc_t1_dir = config.task1_data+cidoc_path\n",
    "\n",
    "dublin_p1_dir = config.playgrd1_data+dublin_path\n",
    "schema_p1_dir = config.playgrd1_data+schema_path\n",
    "cidoc_p1_dir = config.playgrd1_data+cidoc_path\n",
    "\n",
    "dublin_p3_dir = config.playgrd3_data+dublin_path\n",
    "schema_p3_dir = config.playgrd3_data+schema_path\n",
    "cidoc_p3_dir = config.playgrd3_data+cidoc_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce55bf",
   "metadata": {},
   "source": [
    "Create a directory to store the error reports in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"completeness\"\n",
    "report_dir = f\"data/error_reports/{d}/\"\n",
    "Path(report_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdee5ec",
   "metadata": {},
   "source": [
    "For checking URL vaildity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"no_proxy\"] = \"*\"                                                                                                                     # https://docs.python.org/3/library/urllib.request.html \n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}   # As suggested here: https://www.reddit.com/r/learnpython/comments/1ea3r0z/how_to_avoid_http_error_403_forbidden/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5359486",
   "metadata": {},
   "source": [
    "## Content of Fields\n",
    "\n",
    "Review the Dublin Core XML, Schema.org JSON-LD, and CIDOC-CRM JSON-LD metadata records to identify fields without values or where uncertainty about the field's value is expressed (e.g., `unknown`, `not specified`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d8ca0",
   "metadata": {},
   "source": [
    "### Dublin Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the TXT files so all generated metadata can be read, whether or not the XML is well-formed.\n",
    "extension = \".txt\"\n",
    "dublin_file_paths = []\n",
    "dublin_files_t1 = [f for f in os.listdir(dublin_t1_dir) if f.endswith(extension)]\n",
    "dublin_file_paths += [dublin_t1_dir+f for f in dublin_files_t1]\n",
    "dublin_files_p1 = [f for f in os.listdir(dublin_p1_dir) if f.endswith(extension)]\n",
    "dublin_file_paths += [dublin_p1_dir+f for f in dublin_files_p1]\n",
    "dublin_files_p3 = [f for f in os.listdir(dublin_p3_dir) if f.endswith(extension)]\n",
    "dublin_file_paths += [dublin_p3_dir+f for f in dublin_files_p3]\n",
    "dublin_file_paths.sort()\n",
    "total_dc_files = len(dublin_file_paths)\n",
    "print(f\"Total Dublin Core {extension[1:].upper()} files:\", total_dc_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b238ab",
   "metadata": {},
   "source": [
    "#### Empty Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d059b7",
   "metadata": {},
   "source": [
    "Check for empty metadata fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2773c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = re.compile('(<[a-z]+:[a-z]+>|<[a-z=\" ]+>)((unknown|none|na|\"\"|\\?|not specified|\\n|)|[^<>]+(not specified|unknown))(</[a-z]+:[a-z]+>|</[a-z]+>)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_with_empty, empty_fields_per_file, fields_per_file = utils.findEmptyFields(empty, dublin_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a6727",
   "metadata": {},
   "source": [
    "Create a DataFrame with the empty fields data so we can review it as a table.  We'll sort the data so the files with the most empty fields appear at the top and the files without any empty fields appear at the bottom of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c68f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty = pd.DataFrame.from_dict({\"file_path\":dublin_file_paths, \"empty_field_count\":empty_fields_per_file, \"fields\":fields_per_file}).sort_values(by=\"empty_field_count\", ascending=False)\n",
    "df_empty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631d7221",
   "metadata": {},
   "source": [
    "The first five rows of the DataFrame are displayed above and the last five rows of the DataFrame are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_empty.shape[0] == len(dublin_file_paths), \"The new DataFrame should have exactly one row per Dublin Core metadata record (per file).\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b32ab",
   "metadata": {},
   "source": [
    "Create a report showing how many files have different amounts of empty fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c85363",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_field_count_report = pd.DataFrame(df_empty.empty_field_count.value_counts()).rename(columns={\"count\":\"file_count\"})\n",
    "empty_field_count_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc18668",
   "metadata": {},
   "source": [
    "We can see that 44 files don't have any empty fields, and 63 files have 1 or more empty fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a98778",
   "metadata": {},
   "source": [
    "\"Explode\" the DataFrame so that instead of having one row per file, it has one row per metadata field.  For this, we'll remove (\"drop\") all the files that don't have any empty fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefbf349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty_exploded = df_empty.loc[df_empty.empty_field_count > 0].drop(columns=[\"empty_field_count\"]).explode(\"fields\")\n",
    "assert sum(empty_fields_per_file) == df_empty_exploded.shape[0], \"There should be exactly one row per empty field.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4acf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty_exploded.head() # Show the first five rows of the exploded DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e2d40",
   "metadata": {},
   "source": [
    "Let's transform the data again so the DataFrame has a column for the field with an empty value (i.e., the name or attribute of the XML tag) and a column for the value itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = (list(df_empty_exploded.fields))\n",
    "# Extract the tag name or attribute that indicates the Dublin Core field intended. If the tag\n",
    "# is 'dc' and the metadata field is provided as an attribute, such as '<dc element=\"title\">',\n",
    "# then the extracted data will be 'title,' not 'dc.'\n",
    "tags = [re.search('(?<=<)([a-z:]+)(?=>)|(?<=\")[a-z]+(?=\")', field)[0] for field in fields]\n",
    "values_lists = [re.findall('>[^<]*<', field) for field in fields]\n",
    "values = []\n",
    "for v in values_lists:\n",
    "    if len(v) > 0:\n",
    "        values += [v[0][1:-1]]\n",
    "    else:\n",
    "        values += ['']\n",
    "df_empty_exploded.insert(len(df_empty_exploded.columns), \"tag_or_attribute\", tags)\n",
    "df_empty_exploded.insert(len(df_empty_exploded.columns), \"empty_value\", values)\n",
    "df_empty_exploded.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e50b03",
   "metadata": {},
   "source": [
    "Calculate the occurrence of each tag/attribute name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts = pd.DataFrame(df_empty_exploded.tag_or_attribute.value_counts()).reset_index()\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53beb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_values = list(tag_counts.tag_or_attribute)\n",
    "tag_cats = []\n",
    "for t in tag_values:\n",
    "    if \":\" in t:\n",
    "        tag_cats += [t.split(\":\")[-1]]\n",
    "    else:\n",
    "        tag_cats += [t]\n",
    "tag_counts.insert(1, \"category\", tag_cats)\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cats = tag_counts.groupby([\"category\"]).transform(\"sum\")\n",
    "df_cats.insert(0, \"category\", tag_counts.category)\n",
    "df_cats = df_cats.drop(columns=[\"tag_or_attribute\"]).drop_duplicates()\n",
    "df_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21018d61",
   "metadata": {},
   "source": [
    "Calculate the occurrence of each \"empty\" value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = pd.DataFrame(df_empty_exploded.empty_value.value_counts())\n",
    "df_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04923e",
   "metadata": {},
   "source": [
    "Since the new line (`\\n`) and empty string (`\"\"`) characters will show up in the exported CSV file as blank table cells, we'll replace the cells in the `empty values` column for clarity: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff299cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = utils.emptyErrorReportValues(df_values, \"empty_value\")\n",
    "df_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f18d37",
   "metadata": {},
   "source": [
    "Save the reports as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eece4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_standard = \"dublin_core\"\n",
    "data_serialization = \"xml\"\n",
    "report_type = \"empty_field_counts\"\n",
    "df_empty.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_standard = \"dublin_core\"\n",
    "data_serialization = \"xml\"\n",
    "report_type = \"files_per_empty_field_count\"\n",
    "empty_field_count_report.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d75cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_standard = \"dublin_core\"\n",
    "data_serialization = \"xml\"\n",
    "report_type = \"empty_fields_by_file\"\n",
    "df_empty_exploded.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5079641",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_standard = \"dublin_core\"\n",
    "data_serialization = \"xml\"\n",
    "report_type = \"empty_field_tag_counts\"\n",
    "tag_counts.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b287ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_standard = \"dublin_core\"\n",
    "data_serialization = \"xml\"\n",
    "report_type = \"empty_field_tag_category_counts\"\n",
    "df_cats.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359512e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_standard = \"dublin_core\"\n",
    "data_serialization = \"xml\"\n",
    "report_type = \"empty_field_value_counts\"\n",
    "df_values.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efadd2",
   "metadata": {},
   "source": [
    "#### URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33668bf0",
   "metadata": {},
   "source": [
    "##### Namespace URLs\n",
    "First, check that the namespace URLs are well-formed and that they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pattern = re.compile('([a-z]+ns:[a-z]+|[a-z]+ns)=[^>]+( [^>])*(?=>)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91736437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the URLs\n",
    "files_with_urls, url_count_per_file, urls_per_file = [], [], []\n",
    "for file_path in dublin_file_paths:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        f_string = f.read().lower()\n",
    "        \n",
    "        # Look for URLs in the file\n",
    "        has_urls = re.finditer(url_pattern, f_string)\n",
    "        # Save the URLs in a list per file\n",
    "        file_urls = []\n",
    "        for match in has_urls:\n",
    "            url = match[0]\n",
    "            if \" \" in url:\n",
    "                multiple = url.split(\" \")\n",
    "                file_urls = file_urls + multiple\n",
    "                # print(file_urls)\n",
    "            else:\n",
    "                file_urls += [url]\n",
    "        urls_per_file += [file_urls]\n",
    "        url_count_per_file += [len(file_urls)]\n",
    "        \n",
    "        if len(file_urls) > 0:\n",
    "            # Save the file path to the XML version of the file\n",
    "            file_path.replace(\".txt\", \".xml\")\n",
    "            files_with_urls += [file_path]\n",
    "\n",
    "        f.close()\n",
    "\n",
    "print(sum(url_count_per_file), \"URLs found in\", len(files_with_urls), \"files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba5770",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = pd.DataFrame.from_dict({\"file_path\":dublin_file_paths, \"url_count\":url_count_per_file, \"urls\":urls_per_file}).sort_values(by=\"url_count\", ascending=False)\n",
    "url_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = url_df.loc[url_df[\"url_count\"] > 0]  # Keep only files with URLs\n",
    "url_df_exploded = url_df.explode(\"urls\").drop(columns=[\"url_count\"])\n",
    "url_df_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = list(url_df_exploded.urls)\n",
    "print(urls[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c66bc29",
   "metadata": {},
   "source": [
    "Check that each URL is preceded by a namespace and surrounded in quotes (i.e., `xmlns:dc=\"[URL_GOES_HERE]\"`), otherwise the URL was incorrectly included in the metadata record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ea878",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_namespace = '([a-z]+ns:[a-z]+|[a-z]+ns)=\"https?://[a-z0-9\\-._~:/?#@!$&\\'()*+,;=%]+\"'\n",
    "correct_url = 'https?://[a-z0-9\\-._~:/?#@!$&\\'()*+,;=%]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e08cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_namespace, valid_url = [], []\n",
    "for url in urls:\n",
    "    if re.match(correct_namespace, url):\n",
    "        valid_namespace += [True]\n",
    "    else:\n",
    "        valid_namespace += [False]\n",
    "    \n",
    "    if re.search(correct_url, url):\n",
    "        valid_url += [True]\n",
    "    else:\n",
    "        valid_url += [False]\n",
    "\n",
    "url_df_exploded.insert(len(url_df_exploded.columns), \"valid_namespace_format\", valid_namespace)\n",
    "url_df_exploded.insert(len(url_df_exploded.columns), \"valid_url_format\", valid_url)\n",
    "url_df_exploded.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_urls = url_df_exploded.shape[0]\n",
    "print(\"Total URLs:\", total_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdfe389",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_status = pd.DataFrame(url_df_exploded.valid_namespace_format.value_counts()).rename(columns={\"count\":\"total_urls\"})\n",
    "proportions = (url_status[[\"total_urls\"]]/total_urls).values\n",
    "percentages = [f\"{proportion[0]*100:.2f}%\" for proportion in proportions]\n",
    "url_status.insert(len(url_status.columns), \"proportion_of_urls\", percentages)\n",
    "url_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_status2 = pd.DataFrame(url_df_exploded.valid_url_format.value_counts()).rename(columns={\"count\":\"total_urls\"})\n",
    "proportions = (url_status2[[\"total_urls\"]]/total_urls).values\n",
    "percentages = [f\"{proportion[0]*100:.2f}%\" for proportion in proportions]\n",
    "url_status2.insert(len(url_status2.columns), \"proportion_of_urls\", percentages)\n",
    "url_status2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4012dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url_status = url_df_exploded.drop(columns=[\"urls\"]).drop_duplicates()\n",
    "file_url_status = pd.DataFrame(file_url_status.valid_namespace_format.value_counts()).rename(columns={\"count\":\"file_count\"})\n",
    "df_url_status = url_status.join(file_url_status)\n",
    "proportions = (df_url_status[[\"file_count\"]]/total_dc_files).values\n",
    "percentages = [f\"{proportion[0]*100:.2f}%\" for proportion in proportions]\n",
    "df_url_status.insert(len(df_url_status.columns), \"proportion_of_files\", percentages)\n",
    "df_url_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa31cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url_status2 = url_df_exploded.drop(columns=[\"urls\"]).drop_duplicates()\n",
    "file_url_status2 = pd.DataFrame(file_url_status2.valid_url_format.value_counts()).rename(columns={\"count\":\"file_count\"})\n",
    "df_url_status2 = url_status2.join(file_url_status2)\n",
    "proportions = (df_url_status2[[\"file_count\"]]/total_dc_files).values\n",
    "percentages = [f\"{proportion[0]*100:.2f}%\" for proportion in proportions]\n",
    "df_url_status2.insert(len(df_url_status2.columns), \"proportion_of_files\", percentages)\n",
    "df_url_status2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803583a3",
   "metadata": {},
   "source": [
    "Extract the URLs provided, even if not in a valid format within a metadata record, and then check whether the URL exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb451fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_errors = []\n",
    "for url in urls:\n",
    "    clean = re.findall('https?:\\/\\/[^>\"]+', url)\n",
    "    if len(clean) > 0:\n",
    "        clean_url = clean[0]\n",
    "        clean_url = clean_url.strip('\"')\n",
    "        clean_url = clean_url.strip(' ')\n",
    "        try:\n",
    "            url_request = urllib.request.Request(clean_url, headers=headers)\n",
    "            html = urllib.request.urlopen(url_request, timeout=5).read()\n",
    "            request_errors += [\"No error\"]  # Indicates a valid URL (though a manual check is needed to make sure it's a relevant URL)\n",
    "        except Exception as e:\n",
    "            request_errors += [str(e)]\n",
    "    else:\n",
    "        request_errors += [\"Invalid format (no request made)\"]\n",
    "print(\"Finished requests!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df_exploded.insert(len(url_df_exploded.columns), \"request_error\", request_errors)\n",
    "url_df_exploded.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24faa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df_exploded.request_error.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c52a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_errors_df1 = url_df_exploded.loc[url_df_exploded.valid_namespace_format == False]\n",
    "url_errors_df2 = url_df_exploded.loc[url_df_exploded.valid_url_format == False]\n",
    "url_errors_df3 = url_df_exploded.loc[url_df_exploded.request_error == \"HTTP Error 300: Multiple Choices\"]\n",
    "url_errors_df4 = url_df_exploded.loc[url_df_exploded.request_error == \"HTTP Error 404: Not Found\"]\n",
    "url_errors_df = pd.concat([url_errors_df1, url_errors_df2, url_errors_df3, url_errors_df4])\n",
    "url_errors_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f5ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total errors:\", url_errors_df.shape[0])\n",
    "url_errors_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42460f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validity_by_url = pd.DataFrame(url_df_exploded.request_error.value_counts()).rename(columns={\"count\":\"url_count\"})\n",
    "validity_by_file = pd.DataFrame(url_df_exploded.drop(columns=[\"urls\", \"valid_namespace_format\", \"valid_url_format\"]).drop_duplicates().request_error.value_counts()).rename(columns={\"count\":\"file_count\"})\n",
    "validity_stats = validity_by_url.join(validity_by_file, how=\"outer\").reset_index()\n",
    "validity_stats = validity_stats.rename(columns={\"request_error\":\"url_error_type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a211bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_ref_urls = url_errors_df.loc[url_errors_df.valid_namespace_format == False].shape[0]\n",
    "invalid_ref_files = url_errors_df.drop(columns=[\"urls\"]).drop_duplicates()\n",
    "invalid_ref_files = invalid_ref_files.loc[invalid_ref_files.valid_namespace_format == False].shape[0]\n",
    "invalid_ref_df = pd.DataFrame({\"url_error_type\":[\"Invalid reference to namespace\"], \"url_count\":[invalid_ref_urls], \"file_count\":[invalid_ref_files]})\n",
    "validity_stats = pd.concat([validity_stats, invalid_ref_df], ignore_index=True)\n",
    "\n",
    "invalid_ref_urls = url_errors_df.loc[url_errors_df.valid_url_format == False].shape[0]\n",
    "invalid_ref_files = url_errors_df.drop(columns=[\"urls\"]).drop_duplicates()\n",
    "invalid_ref_files = invalid_ref_files.loc[invalid_ref_files.valid_url_format == False].shape[0]\n",
    "invalid_ref_df = pd.DataFrame({\"url_error_type\":[\"Invalid URL format\"], \"url_count\":[invalid_ref_urls], \"file_count\":[invalid_ref_files]})\n",
    "validity_stats = pd.concat([validity_stats, invalid_ref_df], ignore_index=True)\n",
    "\n",
    "validity_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542da62",
   "metadata": {},
   "source": [
    "##### All URLs\n",
    "Next, extract all URLs included in the data, whether or not they're provided as a namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pattern = 'https?://[a-z0-9\\-._~:/?#@!$&\\'()*+,;=%]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f063631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the URLs\n",
    "files_with_urls, url_count_per_file, urls_per_file = [], [], []\n",
    "for file_path in dublin_file_paths:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        f_string = f.read().lower()\n",
    "        \n",
    "        # Look for URLs in the file\n",
    "        has_urls = re.finditer(url_pattern, f_string)\n",
    "        # Save the URLs in a list per file\n",
    "        file_urls = []\n",
    "        for match in has_urls:\n",
    "            url = match[0]\n",
    "            if \" \" in url:\n",
    "                multiple = url.split(\" \")\n",
    "                file_urls = file_urls + multiple\n",
    "                # print(file_urls)\n",
    "            else:\n",
    "                file_urls += [url]\n",
    "        urls_per_file += [file_urls]\n",
    "        url_count_per_file += [len(file_urls)]\n",
    "        \n",
    "        if len(file_urls) > 0:\n",
    "            # Save the file path to the XML version of the file\n",
    "            file_path.replace(\".txt\", \".xml\")\n",
    "            files_with_urls += [file_path]\n",
    "\n",
    "        f.close()\n",
    "\n",
    "print(sum(url_count_per_file), \"URLs found in\", len(files_with_urls), \"files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_url_df = pd.DataFrame.from_dict({\"file_path\":dublin_file_paths, \"url_count\":url_count_per_file, \"urls\":urls_per_file}).sort_values(by=\"url_count\", ascending=False)\n",
    "all_url_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db31e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_url_df = all_url_df.loc[all_url_df[\"url_count\"] > 0]  # Keep only files with URLs\n",
    "all_url_df_exploded = all_url_df.explode(\"urls\").drop(columns=[\"url_count\"]).rename(columns={\"urls\":\"url\"})\n",
    "all_url_df_exploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e83e19",
   "metadata": {},
   "source": [
    "See if any new URLs that aren't namespaces (or intended to be namespaces) were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new columns for both URL DataFrames with only the url, meaning every string should begin with http.\n",
    "urls = list(url_df_exploded[\"urls\"])\n",
    "clean_urls = []\n",
    "for url in urls:\n",
    "    if \"=\" in url:\n",
    "        clean_urls += [url.split('=\"')[-1].strip('\"')]\n",
    "    else:\n",
    "        clean_urls += [url.strip('\"')]\n",
    "url_df_exploded.insert(2, \"clean_url\", clean_urls)\n",
    "url_df_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then compare the pairs of files and cleaned URLs to the newly extracted URL-file pairs by combining the two DataFrames, removing duplicates, and counting what's left\n",
    "sub_url_df = url_df_exploded[[\"file_path\", \"clean_url\"]]\n",
    "urls = sub_url_df.join(all_url_df_exploded.set_index(\"file_path\"), on=\"file_path\", how=\"outer\")\n",
    "urls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(urls.loc[urls.clean_url.isna()].shape)\n",
    "print(urls.loc[urls.url.isna()].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b6dd5b",
   "metadata": {},
   "source": [
    "Look at the 12 newly found URLs (i.e., URLs that aren't namespaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66973edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ns_urls = urls.loc[urls.clean_url.isna()]\n",
    "non_ns_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ea452d",
   "metadata": {},
   "source": [
    "Confirm that all URLs except the 12 above were already found as namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_urls_list = list(urls.loc[~urls.clean_url.isna()].clean_url)\n",
    "url_list = clean_urls_list = list(urls.loc[~urls.clean_url.isna()].url)\n",
    "i, maxI = 0, len(clean_urls_list)\n",
    "while i < maxI:\n",
    "    assert clean_urls_list[0] == url_list[0]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2184fe3b",
   "metadata": {},
   "source": [
    "Check whether each of the newly found URLs is a valid URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944421ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_errors = []\n",
    "non_ns_url_list = list(non_ns_urls.url)\n",
    "for url in non_ns_url_list:\n",
    "        try:\n",
    "            url_request = Request(url.strip(), headers=headers)\n",
    "            html = urlopen(url_request, timeout=10).read()\n",
    "            request_errors += [\"No error\"]  # Indicates a valid URL (though a manual check is needed to make sure it's a relevant URL)\n",
    "        except Exception as e:\n",
    "            request_errors += [str(e)]\n",
    "print(\"Finished requests!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f77d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ns_urls = non_ns_urls.drop(columns=[\"clean_url\"])\n",
    "non_ns_urls.insert(len(non_ns_urls.columns), \"request_error\", request_errors)\n",
    "non_ns_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ns_urls_stats = pd.DataFrame(non_ns_urls.request_error.value_counts())\n",
    "non_ns_urls_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f68db",
   "metadata": {},
   "source": [
    "Save the reports as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_standard = \"dublin_core\"\n",
    "data_serialization = \"xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ba7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"namespace_url_counts\"\n",
    "url_df.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"namespace_url_validity_counts\"\n",
    "df_url_status.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"namespace_url_errors\"\n",
    "url_df_exploded.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48139db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"namespace_url_errors_stats\"\n",
    "validity_stats.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1991746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"non-namespace_url_errors\"\n",
    "non_ns_urls.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5807b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"non-namespace_url_errors_stats\"\n",
    "non_ns_urls_stats.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c590fa6",
   "metadata": {},
   "source": [
    "### JSON-LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = \".txt\" #\".json\"\n",
    "cidoc_file_paths = []\n",
    "cidoc_files_t1 = [f for f in os.listdir(cidoc_t1_dir) if f.endswith(extension)]\n",
    "cidoc_file_paths += [cidoc_t1_dir+f for f in cidoc_files_t1]\n",
    "cidoc_files_p1 = [f for f in os.listdir(cidoc_p1_dir) if f.endswith(extension)]\n",
    "cidoc_file_paths += [cidoc_p1_dir+f for f in cidoc_files_p1]\n",
    "cidoc_files_p3 = [f for f in os.listdir(cidoc_p3_dir) if f.endswith(extension)]\n",
    "cidoc_file_paths += [cidoc_p3_dir+f for f in cidoc_files_p3]\n",
    "cidoc_file_paths.sort()\n",
    "print(\"Total CIDOC-CRM JSON files:\", len(cidoc_file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267746a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cidoc_file_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d88b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = \".txt\" #\".json\"\n",
    "schema_file_paths = []\n",
    "schema_files_t1 = os.listdir(schema_t1_dir)\n",
    "schema_file_paths += [schema_t1_dir+f for f in schema_files_t1 if f.endswith(extension)]\n",
    "schema_files_p1 = os.listdir(schema_p1_dir)\n",
    "schema_file_paths += [schema_p1_dir+f for f in schema_files_p1 if f.endswith(extension)]\n",
    "schema_files_p3 = os.listdir(schema_p3_dir)\n",
    "schema_file_paths += [schema_p3_dir+f for f in schema_files_p3 if f.endswith(extension)]\n",
    "schema_file_paths.sort()\n",
    "print(\"Total Schema.org JSON files:\", len(schema_file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bdb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_file_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70deea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_paths = cidoc_file_paths + schema_file_paths\n",
    "total_json_files = len(json_file_paths)\n",
    "print(len(json_file_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8f4b28",
   "metadata": {},
   "source": [
    "#### Content of Fields\n",
    "Check for empty metadata fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_values = re.compile('((?<=:)\\s*)\"[^\"]+\"')\n",
    "empty = re.compile('(\"[^\"]+\":\\s?)((\"(unknown|none|na|\\?|not specified)\")|\"\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9397b0",
   "metadata": {},
   "source": [
    "First find the empty fields for the metadata records in CIDOC-CRM JSON-LD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa78872",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_with_empty, empty_fields_per_file, fields_per_file = utils.findEmptyFields(empty, cidoc_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d484227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cidoc_empty = pd.DataFrame.from_dict({\"file_path\":cidoc_file_paths, \"model\":[\"CIDOC-CRM\"]*len(cidoc_file_paths), \"empty_field_count\":empty_fields_per_file, \"fields\":fields_per_file}).sort_values(by=\"empty_field_count\", ascending=False)\n",
    "df_cidoc_empty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25baa8cc",
   "metadata": {},
   "source": [
    "Next find the empty fields for the metadata records in Schema.org JSON-LD and add them to the `df_empty` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5770a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_with_empty, empty_fields_per_file, fields_per_file = utils.findEmptyFields(empty, schema_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sdo_empty = pd.DataFrame.from_dict({\"file_path\":schema_file_paths, \"model\":[\"Schema.org\"]*len(schema_file_paths), \"empty_field_count\":empty_fields_per_file, \"fields\":fields_per_file}).sort_values(by=\"empty_field_count\", ascending=False)\n",
    "df_sdo_empty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b13a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty = pd.concat([df_cidoc_empty, df_sdo_empty])\n",
    "df_empty = df_empty.sort_values(by=[\"empty_field_count\"], ascending=False)\n",
    "df_empty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fea5aa",
   "metadata": {},
   "source": [
    "\"Explode\" the DataFrame so that there is one row per field, rather than one row per file.  We'll exclude all the files that don't have any empty fields from this version of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty_exploded = df_empty.loc[df_empty.empty_field_count > 0].drop(columns=[\"empty_field_count\"]).explode(\"fields\")\n",
    "df_empty_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810bb907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty_exploded[[\"field\", \"value\"]] = df_empty_exploded[\"fields\"].str.split(\": \", expand=True)\n",
    "df_empty_exploded.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6350abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_fields = pd.DataFrame(df_empty_exploded.model.value_counts()).rename(columns={\"count\":\"field_count\"})\n",
    "total_empty_fields = df_empty_exploded.shape[0]\n",
    "df_model_files = pd.DataFrame(df_empty.model.value_counts()).rename(columns={\"count\":\"file_count\"})\n",
    "total_files_with_empty = df_empty.shape[0]\n",
    "df_model_totals = df_model_fields.join(df_model_files).reset_index()\n",
    "df_model_totals = pd.concat([df_model_totals, pd.DataFrame.from_dict({\"model\": [\"TOTAL\"], \"field_count\": total_empty_fields, \"file_count\": total_files_with_empty})])\n",
    "df_model_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73227a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"field\"\n",
    "all_field_counts = pd.DataFrame(df_empty_exploded[col].value_counts())\n",
    "sdo_field_counts = pd.DataFrame(df_empty_exploded.loc[df_empty_exploded.model == \"Schema.org\"][col].value_counts())\n",
    "cidoc_field_counts = pd.DataFrame(df_empty_exploded.loc[df_empty_exploded.model == \"CIDOC-CRM\"][col].value_counts())\n",
    "field_counts = all_field_counts.join(sdo_field_counts, rsuffix=\"_sdo_fields\").join(cidoc_field_counts, rsuffix=\"_cidoc_fields\")\n",
    "field_counts = field_counts.rename(columns={\"count\":\"field_count\"})\n",
    "# field_counts\n",
    "subdf = df_empty_exploded[[\"file_path\", \"model\", col]].drop_duplicates()\n",
    "all_file_counts = pd.DataFrame(subdf[col].value_counts())\n",
    "sdo_file_counts = pd.DataFrame(subdf.loc[subdf.model == \"Schema.org\"][col].value_counts())\n",
    "cidoc_file_counts = pd.DataFrame(subdf.loc[subdf.model == \"CIDOC-CRM\"][col].value_counts())\n",
    "file_counts = all_file_counts.join(sdo_file_counts, rsuffix=\"_sdo_files\").join(cidoc_file_counts, rsuffix=\"_cidoc_files\")\n",
    "file_counts = file_counts.rename(columns={\"count\":\"file_count\"})\n",
    "# file_counts\n",
    "field_counts = field_counts.join(file_counts)\n",
    "field_counts = field_counts.fillna(0)\n",
    "field_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"value\"\n",
    "all_value_counts = pd.DataFrame(df_empty_exploded[col].value_counts())\n",
    "sdo_value_counts = pd.DataFrame(df_empty_exploded.loc[df_empty_exploded.model == \"Schema.org\"][col].value_counts())\n",
    "cidoc_value_counts = pd.DataFrame(df_empty_exploded.loc[df_empty_exploded.model == \"CIDOC-CRM\"][col].value_counts())\n",
    "value_counts = all_value_counts.join(sdo_value_counts, rsuffix=\"_sdo_fields\").join(cidoc_value_counts, rsuffix=\"_cidoc_fields\")\n",
    "value_counts = value_counts.rename(columns={\"count\":\"field_count\"})\n",
    "# value_counts\n",
    "subdf = df_empty_exploded[[\"file_path\", \"model\", col]].drop_duplicates()\n",
    "all_file_counts = pd.DataFrame(subdf[col].value_counts())\n",
    "sdo_file_counts = pd.DataFrame(subdf.loc[subdf.model == \"Schema.org\"][col].value_counts())\n",
    "cidoc_file_counts = pd.DataFrame(subdf.loc[subdf.model == \"CIDOC-CRM\"][col].value_counts())\n",
    "file_counts = all_file_counts.join(sdo_file_counts, rsuffix=\"_sdo_files\").join(cidoc_file_counts, rsuffix=\"_cidoc_files\")\n",
    "file_counts = file_counts.rename(columns={\"count\":\"file_count\"})\n",
    "# file_counts\n",
    "value_counts = value_counts.join(file_counts)\n",
    "value_counts = value_counts.fillna(0)\n",
    "\n",
    "# Reformat the empty values column to make sure empty strings (\"\") or newlines (\\n) are visible in the CSV file of this report\n",
    "value_counts = utils.emptyErrorReportValues(value_counts, \"value\")\n",
    "\n",
    "value_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52751b1d",
   "metadata": {},
   "source": [
    "Save the reports as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee679fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_standard = \"sdo-cidoc\"\n",
    "data_serialization = \"json-ld\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"empty_fields_by_file\"\n",
    "df_empty.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"empty_fields_by_field\"\n",
    "df_empty_exploded.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"empty_by_model\"\n",
    "df_model_totals.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"empty_field_counts\"\n",
    "field_counts.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012a01e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"empty_value_counts\"\n",
    "value_counts.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3c1d16",
   "metadata": {},
   "source": [
    "#### URLs\n",
    "Check that URLs are well-formed and that they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdd9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pattern = 'https?://[a-z0-9\\-._~:/?#@!$&\\'()*+,;=%]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28bf6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the URLs\n",
    "files_with_urls, url_count_per_file, urls_per_file = [], [], []\n",
    "for file_path in schema_file_paths:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        f_string = f.read().lower()\n",
    "        \n",
    "        # Look for URLs in the file\n",
    "        has_urls = re.finditer(url_pattern, f_string)\n",
    "        # Save the URLs in a list per file\n",
    "        file_urls = []\n",
    "        for match in has_urls:\n",
    "            url = match[0]\n",
    "            if \" \" in url:\n",
    "                multiple = url.split(\" \")\n",
    "                file_urls = file_urls + multiple\n",
    "                # print(file_urls)\n",
    "            else:\n",
    "                file_urls += [url]\n",
    "        urls_per_file += [file_urls]\n",
    "        url_count_per_file += [len(file_urls)]\n",
    "        \n",
    "        if len(file_urls) > 0:\n",
    "            # Save the file path to the XML version of the file\n",
    "            file_path.replace(\".txt\", \".xml\")\n",
    "            files_with_urls += [file_path]\n",
    "\n",
    "        f.close()\n",
    "\n",
    "print(sum(url_count_per_file), \"URLs found in\", len(files_with_urls), \"files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f98089",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdo_url_df = pd.DataFrame.from_dict({\"file_path\":schema_file_paths, \"model\": [\"Schema.org\"]*len(schema_file_paths), \"url_count\":url_count_per_file, \"urls\":urls_per_file}).sort_values(by=\"url_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the URLs\n",
    "files_with_urls, url_count_per_file, urls_per_file = [], [], []\n",
    "for file_path in cidoc_file_paths:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        f_string = f.read().lower()\n",
    "        \n",
    "        # Look for URLs in the file\n",
    "        has_urls = re.finditer(url_pattern, f_string)\n",
    "        # Save the URLs in a list per file\n",
    "        file_urls = []\n",
    "        for match in has_urls:\n",
    "            url = match[0]\n",
    "            if \" \" in url:\n",
    "                multiple = url.split(\" \")\n",
    "                file_urls = file_urls + multiple\n",
    "                # print(file_urls)\n",
    "            else:\n",
    "                file_urls += [url]\n",
    "        urls_per_file += [file_urls]\n",
    "        url_count_per_file += [len(file_urls)]\n",
    "        \n",
    "        if len(file_urls) > 0:\n",
    "            # Save the file path to the XML version of the file\n",
    "            file_path.replace(\".txt\", \".xml\")\n",
    "            files_with_urls += [file_path]\n",
    "\n",
    "        f.close()\n",
    "\n",
    "print(sum(url_count_per_file), \"URLs found in\", len(files_with_urls), \"files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c5ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cidoc_url_df = pd.DataFrame.from_dict({\"file_path\":cidoc_file_paths, \"model\": [\"CIDOC-CRM\"]*len(cidoc_file_paths), \"url_count\":url_count_per_file, \"urls\":urls_per_file}).sort_values(by=\"url_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ac3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = pd.concat([sdo_url_df, cidoc_url_df])\n",
    "url_df = url_df.sort_values(by=\"url_count\", ascending=False)\n",
    "url_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc00d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = url_df.loc[url_df[\"url_count\"] > 0]  # Keep only files with URLs\n",
    "url_df_exploded = url_df.explode(\"urls\").drop(columns=[\"url_count\"])\n",
    "url_df_exploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da37db6b",
   "metadata": {},
   "source": [
    "Check whether each of the newly found URLs is a valid URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f281627",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_errors = []\n",
    "json_url_list = list(url_df_exploded.urls)\n",
    "for url in json_url_list:\n",
    "        try:\n",
    "            url_request = Request(url.strip(), headers=headers)\n",
    "            html = urlopen(url_request, timeout=10).read()\n",
    "            request_errors += [\"No error\"]  # Indicates a valid URL (though a manual check is needed to make sure it's a relevant URL)\n",
    "        except Exception as e:\n",
    "            request_errors += [str(e)]\n",
    "print(\"Finished requests!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df_exploded.insert(len(url_df_exploded.columns), \"request_error\", request_errors)\n",
    "url_df_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls_df = pd.DataFrame.from_dict({\"model\":[\"TOTAL\"], \"url_count\":[url_df_exploded.shape[0]], \"file_count\":[url_df.shape[0]]}).set_index(\"model\")\n",
    "urls_model_df = pd.DataFrame(url_df_exploded.model.value_counts()).rename(columns={\"count\":\"url_count\"})\n",
    "files_model_df = pd.DataFrame(url_df.model.value_counts()).rename(columns={\"count\":\"file_count\"})\n",
    "model_df = urls_model_df.join(files_model_df)\n",
    "model_df = pd.concat([model_df, all_urls_df])\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2b7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_stats = pd.DataFrame(url_df_exploded.request_error.value_counts())\n",
    "cidoc_error_stats = pd.DataFrame(url_df_exploded.loc[url_df_exploded.model == \"CIDOC-CRM\"].request_error.value_counts()).rename(columns={\"count\":\"cidoc-crm_count\"})\n",
    "schema_error_stats = pd.DataFrame(url_df_exploded.loc[url_df_exploded.model == \"Schema.org\"].request_error.value_counts()).rename(columns={\"count\":\"schema-org_count\"})\n",
    "error_stats = error_stats.join(cidoc_error_stats).join(schema_error_stats).fillna(0)\n",
    "\n",
    "all_errors = url_df_exploded.loc[url_df_exploded.request_error != \"No error\"]\n",
    "cidoc_errors = all_errors.loc[all_errors.model == \"CIDOC-CRM\"].shape[0]\n",
    "schema_errors = all_errors.loc[all_errors.model == \"Schema.org\"].shape[0]\n",
    "total_errors = pd.DataFrame.from_dict({\"request_error\":[\"ALL REQUEST ERRORS\"], \"count\":[all_errors.shape[0]], \"cidoc-crm_count\":[cidoc_errors], \"schema-org_count\":[schema_errors]}).set_index(\"request_error\")\n",
    "\n",
    "error_stats = pd.concat([error_stats, total_errors])\n",
    "error_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9f4549",
   "metadata": {},
   "source": [
    "Save the reports as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2417d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_standard = \"sdo-cidoc\"\n",
    "data_serialization = \"json-ld\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964bab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"url_counts_per_file\"\n",
    "url_df.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24982b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"url_counts_per_model\"\n",
    "model_df.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"urls\" # includes column for request errors\n",
    "url_df_exploded.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf984388",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"url_errors\"\n",
    "all_errors.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = \"url_errors_stats\"\n",
    "error_stats.to_csv(\n",
    "    report_dir+\"{metadata_standard}_{data_serialization}_{report_type}.csv\".format(\n",
    "        metadata_standard=metadata_standard,\n",
    "        data_serialization=data_serialization,\n",
    "        report_type=report_type\n",
    "        ), index=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
